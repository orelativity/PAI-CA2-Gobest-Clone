{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2657afd1",
   "metadata": {},
   "source": [
    "# **Build Time-Series Dataset (Sprint 2 CA2)**\n",
    "\n",
    "### *Objective*\n",
    "Prepare a reusable time-series dataset for **time-series models** (e.g., HMM, LSTM, 1D CNN) using the cleaned datasets from Sprint 1.\n",
    "\n",
    "We will create:\n",
    "1. **Base time-series dataset**: sensor sequences per trip (bookingID), labelled by `is_dangerous_trip`.\n",
    "2. **Hybrid time-series dataset (optional)**: base dataset + **static trip-level engineered features** appended to every timestep (if feature file exists).\n",
    "\n",
    "Outputs are saved to:\n",
    "- `Datasets/time_series_data/`\n",
    "\n",
    "### *Why this is separated from modelling*\n",
    "Time-series formatting (grouping by trip, sorting by time, splitting by bookingID) is **shared** across multiple time-series models.\n",
    "Keeping it in one place avoids:\n",
    "- data leakage (splitting by rows instead of by trip)\n",
    "- inconsistent preprocessing across models\n",
    "- duplicated logic across notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863b554b",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc040023",
   "metadata": {},
   "source": [
    "# **Imports + Paths**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6520c090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_DIR: c:\\PAI-GoBest-Project\\Sprint 2\n",
      "SENSOR_PATH: c:\\PAI-GoBest-Project\\Sprint 2\\Datasets\\cleaned_datasets\\sensor_data_cleaned.csv\n",
      "SAFETY_PATH: c:\\PAI-GoBest-Project\\Sprint 2\\Datasets\\cleaned_datasets\\safety_data_cleaned.csv\n",
      "DRIVER_PATH: c:\\PAI-GoBest-Project\\Sprint 2\\Datasets\\cleaned_datasets\\driver_data_cleaned.csv\n",
      "OUT_DIR: c:\\PAI-GoBest-Project\\Sprint 2\\Datasets\\time_series_data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# base directory = project root (assuming notebook is in Sprint 2/Advanced Data Processing/)\n",
    "BASE_DIR = os.path.dirname(os.getcwd())\n",
    "\n",
    "CLEAN_DIR = os.path.join(BASE_DIR, \"Datasets\", \"cleaned_datasets\")\n",
    "FEAT_DIR  = os.path.join(BASE_DIR, \"Datasets\", \"ca2_features\")  # friend’s features live here\n",
    "OUT_DIR   = os.path.join(BASE_DIR, \"Datasets\", \"time_series_data\")\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "SENSOR_PATH = os.path.join(CLEAN_DIR, \"sensor_data_cleaned.csv\")\n",
    "SAFETY_PATH = os.path.join(CLEAN_DIR, \"safety_data_cleaned.csv\")\n",
    "DRIVER_PATH = os.path.join(CLEAN_DIR, \"driver_data_cleaned.csv\")\n",
    "\n",
    "# (optional) feature-engineered datasets\n",
    "FINAL_FEAT_PATH = os.path.join(FEAT_DIR, \"final_selected_features.csv\")  # most useful if exists\n",
    "COMBINED_FEAT_PATH = os.path.join(FEAT_DIR, \"combined_features.csv\")     # fallback if needed\n",
    "\n",
    "print(\"BASE_DIR:\", BASE_DIR)\n",
    "print(\"SENSOR_PATH:\", SENSOR_PATH)\n",
    "print(\"SAFETY_PATH:\", SAFETY_PATH)\n",
    "print(\"DRIVER_PATH:\", DRIVER_PATH)\n",
    "print(\"OUT_DIR:\", OUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a226ee",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45766db",
   "metadata": {},
   "source": [
    "# **Input datasets (from cleaned_datasets)**\n",
    "\n",
    "##### `sensor_data_cleaned.csv`...\n",
    "Contains high-frequency telematics sensor records, one row per timestep per trip.\n",
    "Key fields:\n",
    "- `bookingID` (trip id)\n",
    "- `second` (time index)\n",
    "- sensor channels (acceleration, gyro, speed, etc.)\n",
    "\n",
    "##### `safety_data_cleaned.csv`...\n",
    "Contains trip-level labels:\n",
    "- `bookingID`\n",
    "- `label` (true/false) or possibly already numeric depending on cleaning\n",
    "\n",
    "##### `driver_data_cleaned.csv`...\n",
    "Driver metadata (static per driver). This is **not time-series**, but can be merged as optional static context later.\n",
    "\n",
    "---\n",
    "\n",
    "### Target label used in Sprint 2\n",
    "We will create:  \n",
    "`is_dangerous_trip` where:\n",
    "- 0 = safe\n",
    "- 1 = dangerous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f84796f",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7f5e00",
   "metadata": {},
   "source": [
    "# **Load Cleaned Datasets**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "610648ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensor shape: (7236579, 12)\n",
      "safety shape: (20000, 3)\n",
      "driver shape: (500, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>bookingID</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>bearing</th>\n",
       "      <th>acceleration_x</th>\n",
       "      <th>acceleration_y</th>\n",
       "      <th>acceleration_z</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "      <th>second</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3394724</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>143.298294</td>\n",
       "      <td>-1.706207</td>\n",
       "      <td>-9.270792</td>\n",
       "      <td>-1.209448</td>\n",
       "      <td>-0.028965</td>\n",
       "      <td>-0.032652</td>\n",
       "      <td>0.015390</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.228454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>436148</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>143.298294</td>\n",
       "      <td>-1.416705</td>\n",
       "      <td>-9.548032</td>\n",
       "      <td>-1.860977</td>\n",
       "      <td>-0.022413</td>\n",
       "      <td>0.005049</td>\n",
       "      <td>-0.025753</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.228454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5786266</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>143.298294</td>\n",
       "      <td>-0.346924</td>\n",
       "      <td>-9.532629</td>\n",
       "      <td>-1.204663</td>\n",
       "      <td>0.014962</td>\n",
       "      <td>-0.050033</td>\n",
       "      <td>0.025118</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.228454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   record_id  bookingID  accuracy     bearing  acceleration_x  acceleration_y  \\\n",
       "0    3394724          0       8.0  143.298294       -1.706207       -9.270792   \n",
       "1     436148          0       8.0  143.298294       -1.416705       -9.548032   \n",
       "2    5786266          0       8.0  143.298294       -0.346924       -9.532629   \n",
       "\n",
       "   acceleration_z    gyro_x    gyro_y    gyro_z  second     speed  \n",
       "0       -1.209448 -0.028965 -0.032652  0.015390     2.0  0.228454  \n",
       "1       -1.860977 -0.022413  0.005049 -0.025753     3.0  0.228454  \n",
       "2       -1.204663  0.014962 -0.050033  0.025118     9.0  0.228454  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookingID</th>\n",
       "      <th>driver_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>359</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>313</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bookingID  driver_id  label\n",
       "0          0        359  False\n",
       "1          1        313   True\n",
       "2          2         27   True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>no_of_years_driving_exp</th>\n",
       "      <th>gender</th>\n",
       "      <th>car_make</th>\n",
       "      <th>car_model_year</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Sinclair Birmingham</td>\n",
       "      <td>1982-10-17</td>\n",
       "      <td>10</td>\n",
       "      <td>Male</td>\n",
       "      <td>Audi</td>\n",
       "      <td>2010</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Juline Faulks</td>\n",
       "      <td>1977-11-30</td>\n",
       "      <td>14</td>\n",
       "      <td>Female</td>\n",
       "      <td>BMW</td>\n",
       "      <td>2000</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Germayne Stit</td>\n",
       "      <td>1976-09-18</td>\n",
       "      <td>13</td>\n",
       "      <td>Male</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>1999</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                 name date_of_birth  no_of_years_driving_exp  gender  \\\n",
       "0   1  Sinclair Birmingham    1982-10-17                       10    Male   \n",
       "1   2        Juline Faulks    1977-11-30                       14  Female   \n",
       "2   3        Germayne Stit    1976-09-18                       13    Male   \n",
       "\n",
       "        car_make  car_model_year  rating  \n",
       "0           Audi            2010     3.8  \n",
       "1            BMW            2000     2.8  \n",
       "2  Mercedes-Benz            1999     3.8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sensor = pd.read_csv(SENSOR_PATH)\n",
    "safety = pd.read_csv(SAFETY_PATH)\n",
    "driver = pd.read_csv(DRIVER_PATH)\n",
    "\n",
    "print(\"sensor shape:\", sensor.shape)\n",
    "print(\"safety shape:\", safety.shape)\n",
    "print(\"driver shape:\", driver.shape)\n",
    "\n",
    "display(sensor.head(3))\n",
    "display(safety.head(3))\n",
    "display(driver.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1108ad0e",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d58b4a7",
   "metadata": {},
   "source": [
    "# **Label normalization**\n",
    "\n",
    "The cleaned `safety_data_cleaned.csv` may store labels as:\n",
    "- `true/false` strings, or\n",
    "- boolean, or\n",
    "- already numeric.\n",
    "\n",
    "For consistency across modelling and GUI, we standardize to:\n",
    "\n",
    "`is_dangerous_trip` ∈ {0, 1}\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f09fe59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   bookingID  is_dangerous_trip\n",
      "0          0                  0\n",
      "1          1                  1\n",
      "2          2                  1\n",
      "3          4                  1\n",
      "4          6                  0\n",
      "label distribution:\n",
      " is_dangerous_trip\n",
      "0    15007\n",
      "1     4993\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# safety schema example: bookingID, driver_id, label\n",
    "# normalize label -> is_dangerous_trip (0/1)\n",
    "\n",
    "safety = safety.copy()\n",
    "\n",
    "if \"is_dangerous_trip\" in safety.columns:\n",
    "    # already normalized\n",
    "    safety[\"is_dangerous_trip\"] = safety[\"is_dangerous_trip\"].astype(int)\n",
    "else:\n",
    "    if \"label\" not in safety.columns:\n",
    "        raise ValueError(\"Expected safety_data_cleaned.csv to contain 'label' or 'is_dangerous_trip'\")\n",
    "\n",
    "    # handle common encodings\n",
    "    if safety[\"label\"].dtype == \"bool\":\n",
    "        safety[\"is_dangerous_trip\"] = safety[\"label\"].astype(int)\n",
    "    else:\n",
    "        # string true/false or mixed\n",
    "        safety[\"label_norm\"] = safety[\"label\"].astype(str).str.lower().str.strip()\n",
    "        safety[\"is_dangerous_trip\"] = safety[\"label_norm\"].map({\n",
    "            \"true\": 1, \"1\": 1, \"yes\": 1,\n",
    "            \"false\": 0, \"0\": 0, \"no\": 0\n",
    "        })\n",
    "\n",
    "        # if any unmapped values remain, surface them early\n",
    "        bad = safety[safety[\"is_dangerous_trip\"].isna()][\"label\"].unique()\n",
    "        if len(bad) > 0:\n",
    "            raise ValueError(f\"Unrecognized label values in safety data: {bad}\")\n",
    "\n",
    "        safety[\"is_dangerous_trip\"] = safety[\"is_dangerous_trip\"].astype(int)\n",
    "\n",
    "print(safety[[\"bookingID\", \"is_dangerous_trip\"]].head())\n",
    "print(\"label distribution:\\n\", safety[\"is_dangerous_trip\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c510935",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b97037",
   "metadata": {},
   "source": [
    "# **Merge trip labels into sensor rows**\n",
    "\n",
    "We join `sensor_data_cleaned` with `safety_data_cleaned` by `bookingID` so that every sensor record inherits the trip label.\n",
    "\n",
    "This is required because time-series models learn from the **sequence**, but the label is defined at the **trip level**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9db04e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after merge shape: (7236579, 13)\n",
      "missing labels: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>bookingID</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>bearing</th>\n",
       "      <th>acceleration_x</th>\n",
       "      <th>acceleration_y</th>\n",
       "      <th>acceleration_z</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "      <th>second</th>\n",
       "      <th>speed</th>\n",
       "      <th>is_dangerous_trip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3394724</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>143.298294</td>\n",
       "      <td>-1.706207</td>\n",
       "      <td>-9.270792</td>\n",
       "      <td>-1.209448</td>\n",
       "      <td>-0.028965</td>\n",
       "      <td>-0.032652</td>\n",
       "      <td>0.015390</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.228454</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>436148</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>143.298294</td>\n",
       "      <td>-1.416705</td>\n",
       "      <td>-9.548032</td>\n",
       "      <td>-1.860977</td>\n",
       "      <td>-0.022413</td>\n",
       "      <td>0.005049</td>\n",
       "      <td>-0.025753</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.228454</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5786266</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>143.298294</td>\n",
       "      <td>-0.346924</td>\n",
       "      <td>-9.532629</td>\n",
       "      <td>-1.204663</td>\n",
       "      <td>0.014962</td>\n",
       "      <td>-0.050033</td>\n",
       "      <td>0.025118</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.228454</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4176046</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>143.298294</td>\n",
       "      <td>-0.600986</td>\n",
       "      <td>-9.452029</td>\n",
       "      <td>-2.157507</td>\n",
       "      <td>0.004548</td>\n",
       "      <td>-0.011713</td>\n",
       "      <td>-0.004078</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.228454</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4528581</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>143.298294</td>\n",
       "      <td>-0.597546</td>\n",
       "      <td>-9.863403</td>\n",
       "      <td>-1.672711</td>\n",
       "      <td>-0.000401</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>-0.009830</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.228454</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   record_id  bookingID  accuracy     bearing  acceleration_x  acceleration_y  \\\n",
       "0    3394724          0       8.0  143.298294       -1.706207       -9.270792   \n",
       "1     436148          0       8.0  143.298294       -1.416705       -9.548032   \n",
       "2    5786266          0       8.0  143.298294       -0.346924       -9.532629   \n",
       "3    4176046          0       8.0  143.298294       -0.600986       -9.452029   \n",
       "4    4528581          0       8.0  143.298294       -0.597546       -9.863403   \n",
       "\n",
       "   acceleration_z    gyro_x    gyro_y    gyro_z  second     speed  \\\n",
       "0       -1.209448 -0.028965 -0.032652  0.015390     2.0  0.228454   \n",
       "1       -1.860977 -0.022413  0.005049 -0.025753     3.0  0.228454   \n",
       "2       -1.204663  0.014962 -0.050033  0.025118     9.0  0.228454   \n",
       "3       -2.157507  0.004548 -0.011713 -0.004078    11.0  0.228454   \n",
       "4       -1.672711 -0.000401  0.000315 -0.009830    12.0  0.228454   \n",
       "\n",
       "   is_dangerous_trip  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = sensor.merge(\n",
    "    safety[[\"bookingID\", \"is_dangerous_trip\"]],\n",
    "    on=\"bookingID\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "print(\"after merge shape:\", df.shape)\n",
    "\n",
    "# sanity: all trips in df should have a label\n",
    "missing = df[\"is_dangerous_trip\"].isna().sum()\n",
    "print(\"missing labels:\", missing)\n",
    "\n",
    "# check time column exists\n",
    "if \"second\" not in df.columns:\n",
    "    raise ValueError(\"Expected sensor data to contain 'second' for time ordering.\")\n",
    "\n",
    "# sort for correct sequencing\n",
    "df = df.sort_values([\"bookingID\", \"second\"]).reset_index(drop=True)\n",
    "\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a9cf1d",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d2ecb4",
   "metadata": {},
   "source": [
    "# **Feature selection for time-series (base channels)**\n",
    "\n",
    "For time-series models, we keep raw sensor channels as **sequence observations**.\n",
    "We intentionally avoid rolling statistics or aggregations here, because those belong to feature engineering and/or tabular models.\n",
    "\n",
    "### Base observation channels (recommended)\n",
    "- `speed`\n",
    "- `acceleration_x, acceleration_y, acceleration_z`\n",
    "- `gyro_x, gyro_y, gyro_z`\n",
    "Optionally:\n",
    "- `bearing`, `accuracy` (GPS quality signals)\n",
    "\n",
    "We will:\n",
    "1. choose a stable column list\n",
    "2. drop rows with missing values in those columns\n",
    "3. keep the dataset in **long format** (one row = one timestep)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe5011f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using obs_cols: ['speed', 'acceleration_x', 'acceleration_y', 'acceleration_z', 'gyro_x', 'gyro_y', 'gyro_z', 'bearing', 'accuracy']\n",
      "Dropped 0 rows due to NaNs in obs cols (7236579 -> 7236579)\n"
     ]
    }
   ],
   "source": [
    "# choose observation columns that likely exist\n",
    "candidate_cols = [\n",
    "    \"speed\",\n",
    "    \"acceleration_x\", \"acceleration_y\", \"acceleration_z\",\n",
    "    \"gyro_x\", \"gyro_y\", \"gyro_z\",\n",
    "    \"bearing\", \"accuracy\"\n",
    "]\n",
    "\n",
    "obs_cols = [c for c in candidate_cols if c in df.columns]\n",
    "\n",
    "if len(obs_cols) < 4:\n",
    "    raise ValueError(f\"Too few observation columns found. Available obs cols: {obs_cols}\")\n",
    "\n",
    "print(\"Using obs_cols:\", obs_cols)\n",
    "\n",
    "before = len(df)\n",
    "df = df.dropna(subset=obs_cols)\n",
    "after = len(df)\n",
    "print(f\"Dropped {before-after} rows due to NaNs in obs cols ({before} -> {after})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053ea426",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad2e8f1",
   "metadata": {},
   "source": [
    "# **Optional static context features (if applicable)**\n",
    "\n",
    "Time-series models can optionally use **static features** (per trip) such as:\n",
    "- driver profile (age, experience, car model year, rating)\n",
    "- engineered per-trip features (tsfresh/manual aggregates)\n",
    "\n",
    "### Important note\n",
    "- For **HMM**, adding many static features is usually NOT helpful because HMM assumes emissions are generated per timestep.\n",
    "- For neural time-series models (LSTM/CNN), static features can be appended as extra channels repeated over time (constant across timesteps).\n",
    "\n",
    "So we will build:\n",
    "1. **Base dataset**: time-series sensor channels only (best for HMM baseline).\n",
    "2. **Hybrid dataset (optional)**: base + engineered static features repeated per timestep (for neural models later).\n",
    "\n",
    "If the engineered feature file is missing, we simply skip hybrid output.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "287a5373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded engineered features from: c:\\PAI-GoBest-Project\\Sprint 2\\Datasets\\ca2_features\\final_selected_features.csv\n",
      "Engineered numeric feature count: 11\n"
     ]
    }
   ],
   "source": [
    "df_enriched = df.copy()\n",
    "\n",
    "# ---- Optional driver info (static per driver_id) ----\n",
    "# safety has driver_id, sensor doesn't. So merge driver_id first.\n",
    "if \"driver_id\" in safety.columns:\n",
    "    df_enriched = df_enriched.merge(\n",
    "        safety[[\"bookingID\", \"driver_id\"]],\n",
    "        on=\"bookingID\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # derive driver-level features that are safe to include as static context\n",
    "    driver2 = driver.copy()\n",
    "    driver2[\"date_of_birth\"] = pd.to_datetime(driver2[\"date_of_birth\"], errors=\"coerce\")\n",
    "\n",
    "    # crude age feature based on dataset dates not provided, so we use year only\n",
    "    # (document this limitation; alternatively omit age entirely)\n",
    "    driver2[\"birth_year\"] = driver2[\"date_of_birth\"].dt.year\n",
    "\n",
    "    # categorical encoding left for modelling stage; here we keep raw columns\n",
    "    driver_keep = [\"id\", \"no_of_years_driving_exp\", \"gender\", \"car_make\", \"car_model_year\", \"rating\", \"birth_year\"]\n",
    "    driver_keep = [c for c in driver_keep if c in driver2.columns]\n",
    "\n",
    "    df_enriched = df_enriched.merge(\n",
    "        driver2[driver_keep].rename(columns={\"id\": \"driver_id\"}),\n",
    "        on=\"driver_id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "else:\n",
    "    print(\"No driver_id found in safety. Skipping driver enrichment.\")\n",
    "\n",
    "# ---- Optional engineered trip-level features ----\n",
    "feat_path = None\n",
    "if os.path.exists(FINAL_FEAT_PATH):\n",
    "    feat_path = FINAL_FEAT_PATH\n",
    "elif os.path.exists(COMBINED_FEAT_PATH):\n",
    "    feat_path = COMBINED_FEAT_PATH\n",
    "\n",
    "engineered_cols = []\n",
    "if feat_path:\n",
    "    feats = pd.read_csv(feat_path)\n",
    "    if \"bookingID\" not in feats.columns:\n",
    "        print(f\"Engineered feature file found but no bookingID column: {feat_path}. Skipping.\")\n",
    "    else:\n",
    "        # Keep only numeric engineered features to avoid exploding the dataset with strings\n",
    "        numeric_feats = feats.select_dtypes(include=[np.number]).copy()\n",
    "        numeric_feats[\"bookingID\"] = feats[\"bookingID\"]\n",
    "\n",
    "        engineered_cols = [c for c in numeric_feats.columns if c != \"bookingID\"]\n",
    "        print(f\"Loaded engineered features from: {feat_path}\")\n",
    "        print(f\"Engineered numeric feature count: {len(engineered_cols)}\")\n",
    "\n",
    "        df_enriched = df_enriched.merge(numeric_feats, on=\"bookingID\", how=\"left\")\n",
    "else:\n",
    "    print(\"No engineered feature CSV found. Hybrid dataset will not include engineered features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15596066",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4071842",
   "metadata": {},
   "source": [
    "# **Output design (CSV, long format)**\n",
    "\n",
    "We save time-series data in **long format**:\n",
    "- one row = one timestep record\n",
    "- grouped by `bookingID`\n",
    "- ordered by `second`\n",
    "\n",
    "### Files saved\n",
    "- `timeseries_v1_base.csv`\n",
    "  - columns: `bookingID`, `second`, `is_dangerous_trip`, obs_cols\n",
    "- `timeseries_v1_hybrid.csv` (only if engineered features exist)\n",
    "  - includes base + static context (driver + engineered numeric)\n",
    "\n",
    "### Why long format?\n",
    "It stays compatible with:\n",
    "- HMM (groupby bookingID -> sequences)\n",
    "- LSTM/CNN (same grouping)\n",
    "- batch inference in GUI (CSV upload)\n",
    "\n",
    "We avoid “sequence-in-one-cell” formats because they are fragile and hard to debug.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec3b22b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\PAI-GoBest-Project\\Sprint 2\\Datasets\\time_series_data\\timeseries_v1_base.csv | shape: (7236579, 12)\n",
      "Saved: c:\\PAI-GoBest-Project\\Sprint 2\\Datasets\\time_series_data\\timeseries_v1_hybrid.csv | shape: (7236579, 27)\n"
     ]
    }
   ],
   "source": [
    "VERSION = \"v1\"\n",
    "\n",
    "base_cols = [\"bookingID\", \"second\", \"is_dangerous_trip\"] + obs_cols\n",
    "base_out = df[base_cols].copy()\n",
    "\n",
    "base_path = os.path.join(OUT_DIR, f\"timeseries_{VERSION}_base.csv\")\n",
    "base_out.to_csv(base_path, index=False)\n",
    "print(\"Saved:\", base_path, \"| shape:\", base_out.shape)\n",
    "\n",
    "# hybrid output only if we actually added anything meaningful\n",
    "hybrid_path = None\n",
    "added_cols = [c for c in df_enriched.columns if c not in df.columns]\n",
    "\n",
    "# we consider hybrid \"valid\" if it includes engineered features OR driver features\n",
    "has_engineered = len(engineered_cols) > 0\n",
    "has_driver = any(c in df_enriched.columns for c in [\"no_of_years_driving_exp\", \"rating\", \"car_model_year\", \"birth_year\"])\n",
    "\n",
    "if has_engineered or has_driver:\n",
    "    # keep a controlled set of columns to prevent huge file bloat\n",
    "    hybrid_keep = [\"bookingID\", \"second\", \"is_dangerous_trip\"] + obs_cols\n",
    "\n",
    "    # include driver statics if present\n",
    "    driver_statics = [\"no_of_years_driving_exp\", \"car_model_year\", \"rating\", \"birth_year\"]\n",
    "    driver_statics = [c for c in driver_statics if c in df_enriched.columns]\n",
    "\n",
    "    # include engineered numeric\n",
    "    engineered_keep = engineered_cols[:]  # already numeric\n",
    "\n",
    "    hybrid_keep += driver_statics + engineered_keep\n",
    "\n",
    "    hybrid_out = df_enriched[hybrid_keep].copy()\n",
    "    hybrid_path = os.path.join(OUT_DIR, f\"timeseries_{VERSION}_hybrid.csv\")\n",
    "    hybrid_out.to_csv(hybrid_path, index=False)\n",
    "    print(\"Saved:\", hybrid_path, \"| shape:\", hybrid_out.shape)\n",
    "else:\n",
    "    print(\"Hybrid output skipped (no engineered/driver static features available).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79365eb",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e7c97a",
   "metadata": {},
   "source": [
    "# **Train/Test split strategy (trip-based)**\n",
    "\n",
    "Time-series leakage happens when we split **by rows**:\n",
    "- The same trip contributes timesteps to both train and test\n",
    "- Models appear unrealistically strong\n",
    "\n",
    "To prevent leakage, we split by:\n",
    "- unique `bookingID` (trip)\n",
    "\n",
    "We save:\n",
    "- `timeseries_v1_trip_split.csv`\n",
    "\n",
    "This ensures **all time-series models** (HMM, LSTM, CNN) use the same split for fair comparison.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2e040ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: c:\\PAI-GoBest-Project\\Sprint 2\\Datasets\\time_series_data\\timeseries_v1_trip_split.csv\n",
      "split\n",
      "train    15977\n",
      "test      3995\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "split_seed = 42\n",
    "test_size = 0.2\n",
    "\n",
    "trip_labels = base_out[[\"bookingID\", \"is_dangerous_trip\"]].drop_duplicates()\n",
    "\n",
    "train_ids, test_ids = train_test_split(\n",
    "    trip_labels[\"bookingID\"].values,\n",
    "    test_size=test_size,\n",
    "    random_state=split_seed,\n",
    "    stratify=trip_labels[\"is_dangerous_trip\"].values\n",
    ")\n",
    "\n",
    "split_df = pd.DataFrame({\n",
    "    \"bookingID\": np.concatenate([train_ids, test_ids]),\n",
    "    \"split\": ([\"train\"] * len(train_ids)) + ([\"test\"] * len(test_ids))\n",
    "})\n",
    "\n",
    "split_path = os.path.join(OUT_DIR, f\"timeseries_{VERSION}_trip_split.csv\")\n",
    "split_df.to_csv(split_path, index=False)\n",
    "\n",
    "print(\"Saved:\", split_path)\n",
    "print(split_df[\"split\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df58c834",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47745cef",
   "metadata": {},
   "source": [
    "# **Verification checks**\n",
    "\n",
    "We validate:\n",
    "1. Every `bookingID` has exactly one label\n",
    "2. Time ordering is correct (`second` increasing within each trip)\n",
    "3. Split integrity: no overlap between train and test trip IDs\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47e5f96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trips with >1 label: 0\n",
      "bookingID=962072674469 | time sorted: True\n",
      "bookingID=231928234145 | time sorted: True\n",
      "bookingID=1597727834251 | time sorted: True\n",
      "bookingID=755914244122 | time sorted: True\n",
      "bookingID=1391569403968 | time sorted: True\n",
      "Split overlap count: 0\n"
     ]
    }
   ],
   "source": [
    "# 1) label uniqueness\n",
    "label_check = base_out.groupby(\"bookingID\")[\"is_dangerous_trip\"].nunique()\n",
    "bad_trips = label_check[label_check > 1]\n",
    "print(\"Trips with >1 label:\", len(bad_trips))\n",
    "if len(bad_trips) > 0:\n",
    "    display(bad_trips.head())\n",
    "\n",
    "# 2) time monotonicity (sample a few trips)\n",
    "sample_trips = base_out[\"bookingID\"].drop_duplicates().sample(5, random_state=split_seed).tolist()\n",
    "for bid in sample_trips:\n",
    "    seconds = base_out.loc[base_out[\"bookingID\"] == bid, \"second\"].values\n",
    "    ok = np.all(np.diff(seconds) >= 0)\n",
    "    print(f\"bookingID={bid} | time sorted:\", ok)\n",
    "\n",
    "# 3) split overlap\n",
    "train_set = set(train_ids)\n",
    "test_set = set(test_ids)\n",
    "overlap = train_set.intersection(test_set)\n",
    "print(\"Split overlap count:\", len(overlap))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107916b4",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b151098",
   "metadata": {},
   "source": [
    "# **Summary of outputs**\n",
    "\n",
    "Created time-series datasets stored in `Datasets/time_series_data/`:\n",
    "\n",
    "- `timeseries_v1_base.csv`  \n",
    "  Long-format sensor time-series data, labelled per trip. Suitable for HMM baseline and all time-series models.\n",
    "\n",
    "- `timeseries_v1_hybrid.csv` (optional)  \n",
    "  If engineered features exist, static trip-level numeric features are merged and repeated per timestep.\n",
    "  This is mainly intended for neural sequence models (LSTM/CNN) rather than HMM.\n",
    "\n",
    "- `timeseries_v1_trip_split.csv`  \n",
    "  Trip-based train/test split (by bookingID) to prevent data leakage and ensure fair comparison across time-series models.\n",
    "\n",
    "### Key design choices and justification\n",
    "- Long-format CSV is readable, consistent with the rest of the project, and compatible with batch + real-time processing later.\n",
    "- Train/test split is performed at trip-level (bookingID) to avoid leakage.\n",
    "- Engineered trip-level features are included only as optional static context because they are not true sequential observations.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
